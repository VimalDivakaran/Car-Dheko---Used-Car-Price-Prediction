{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from nested dictionaries\n",
    "def extract_details(row):\n",
    "    details = row.get('new_car_detail', {})\n",
    "    overview = row.get('new_car_overview', {})\n",
    "    features = row.get('new_car_feature', {})\n",
    "    specs = row.get('new_car_specs', {})\n",
    "    \n",
    "    # Extracting fields from details\n",
    "    ignition_type = details.get('it')\n",
    "    fuel_type = details.get('ft')\n",
    "    body_type = details.get('bt')\n",
    "    kilometers = details.get('km')\n",
    "    transmission = details.get('transmission')\n",
    "    owner_no = details.get('ownerNo')\n",
    "    owner = details.get('owner')\n",
    "    manufacturer = details.get('oem')\n",
    "    car_model = details.get('model')\n",
    "    model_year = details.get('modelYear')\n",
    "    central_variant_id = details.get('centralVariantId')\n",
    "    variant_name = details.get('variantName')\n",
    "    car_price = details.get('price')\n",
    "    price_actual = details.get('priceActual')\n",
    "    price_saving = details.get('priceSaving')\n",
    "    priceFixedText = details.get('priceFixedText')\n",
    "    trendingText = details.get('trendingText')\n",
    "    heading = details.get('heading')\n",
    "    car_links = row.get('car_links')\n",
    "\n",
    "    \n",
    "    # Extracting fields from overview (like registration year, model, etc.)\n",
    "    overview_dict = {item['key']: item['value'] for item in overview.get('top', [])}\n",
    "    \n",
    "    # Extracting features (listing them as comma-separated values)\n",
    "    feature_list = [feature['value'] for feature in features.get('top', [])]\n",
    "    feature_str = ', '.join(feature_list)\n",
    "    \n",
    "    # Extracting specifications (like engine power, mileage, etc.)\n",
    "    specs_dict = {item['key']: item['value'] for item in specs.get('top', [])}\n",
    "    detailed_specs = {}\n",
    "    for category in specs.get('data', []):\n",
    "        for item in category.get('list', []):\n",
    "            detailed_specs[item['key']] = item['value']\n",
    "\n",
    "     # Return a flattened structure\n",
    "    return pd.Series({\n",
    "            'ignition_type': ignition_type,\n",
    "            'fuel_type': fuel_type,\n",
    "            'body_type': body_type,\n",
    "            'kilometers_driven': kilometers,\n",
    "            'transmission': transmission,\n",
    "            'owner_no': owner_no,\n",
    "            'owner': owner,\n",
    "            'manufacturer': manufacturer,\n",
    "            'model': car_model,\n",
    "            'model_year': model_year,\n",
    "            'central_variant_id': central_variant_id,\n",
    "            'variant_name': variant_name,\n",
    "            'price': car_price,\n",
    "            'priceActual': price_actual,\n",
    "            'priceSaving': price_saving,\n",
    "            'priceFixedText': priceFixedText,\n",
    "            'trendingText': trendingText,\n",
    "            'heading': heading ,\n",
    "            'car_links': car_links,\n",
    "            'features': feature_str,\n",
    "            'registration_year': overview_dict.get('Registration Year'),\n",
    "            'insurance': overview_dict.get('Insurance Validity'),\n",
    "            'Fuel_type': overview_dict.get('Fuel Type'),\n",
    "            'kms_driven': overview_dict.get('Kms Driven'),\n",
    "            'rto': overview_dict.get('RTO'),\n",
    "            'ownership': overview_dict.get('Ownership'),\n",
    "            'engine_displacement': overview_dict.get('Engine Displacement'),\n",
    "            'Transmission': overview_dict.get('Transmission'),\n",
    "            'year_of_manufacture': overview_dict.get('Year of Manufacture'),\n",
    "            'engine': specs_dict.get('Engine'),\n",
    "            'max_power': specs_dict.get('Max Power'),\n",
    "            'torque': specs_dict.get('Torque'),\n",
    "            'wheel_size': specs_dict.get('Wheel Size'),\n",
    "            'seats': specs_dict.get('Seats'),\n",
    "            'color': detailed_specs.get('Color'),\n",
    "            'engine_type': detailed_specs.get('Engine Type'),\n",
    "            'displacement': detailed_specs.get('Displacement'),\n",
    "            'engine_max_power': detailed_specs.get('Max Power'),\n",
    "            'engine_max_torque': detailed_specs.get('Max Torque'),\n",
    "            'no_of_cylinders': detailed_specs.get('No of Cylinder'),\n",
    "            'values_per_cylinder': detailed_specs.get('Values per Cylinder'),\n",
    "            'fuel_suppy_system': detailed_specs.get('Fuel Suppy System'),\n",
    "            'turbo_charger': detailed_specs.get('Turbo Charger'),\n",
    "            'length': detailed_specs.get('Length'),\n",
    "            'width': detailed_specs.get('Width'),\n",
    "            'height': detailed_specs.get('Height'),\n",
    "            'wheel_base': detailed_specs.get('Wheel Base'),\n",
    "            'kerb_weight': detailed_specs.get('Kerb Weight'),\n",
    "            'gear_box': detailed_specs.get('Gear Box'),\n",
    "            'drive_type': detailed_specs.get('Drive Type'),\n",
    "            'steering_type': detailed_specs.get('Steering Type'),\n",
    "            'seating_capacity': detailed_specs.get('Seating Capacity'),\n",
    "            'front_brake_type': detailed_specs.get('Front Brake Type'),\n",
    "            'rear_brake_type': detailed_specs.get('Rear Brake Type'),\n",
    "            'tyre_type': detailed_specs.get('Tyre Type'),\n",
    "            'alloy_wheel_size': detailed_specs.get('Alloy Wheel Size'),\n",
    "            'no_of_doors': detailed_specs.get('No Door Numbers'),\n",
    "            'cargo_volumn': detailed_specs.get('Cargo Volumn')\n",
    "        })\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chennai_cars\n",
    "# Load the dataset with the correct engine\n",
    "data = pd.read_excel('chennai_cars.xlsx')\n",
    "\n",
    "# Convert string representations of dictionaries into actual dictionaries\n",
    "data['new_car_detail'] = data['new_car_detail'].apply(ast.literal_eval)\n",
    "data['new_car_overview'] = data['new_car_overview'].apply(ast.literal_eval)\n",
    "data['new_car_feature'] = data['new_car_feature'].apply(ast.literal_eval)\n",
    "data['new_car_specs'] = data['new_car_specs'].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "# Apply the extraction function to each row\n",
    "chennai_df = data.apply(extract_details, axis=1)\n",
    "chennai_df['City']='Chennai'\n",
    "\n",
    "# Display the structured dataset\n",
    "print(chennai_df.head())\n",
    "\n",
    "# Save the structured data to a new Excel file (optional)\n",
    "chennai_df.to_csv('chennai_cars.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chennai_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyderabad Cars\n",
    "\n",
    "# Load the dataset \n",
    "data = pd.read_excel('hyderabad_cars.xlsx')\n",
    "\n",
    "# Convert string representations of dictionaries into actual dictionaries\n",
    "data['new_car_detail'] = data['new_car_detail'].apply(ast.literal_eval)\n",
    "data['new_car_overview'] = data['new_car_overview'].apply(ast.literal_eval)\n",
    "data['new_car_feature'] = data['new_car_feature'].apply(ast.literal_eval)\n",
    "data['new_car_specs'] = data['new_car_specs'].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "# Apply the extraction function to each row\n",
    "hyderabad_df = data.apply(extract_details, axis=1)\n",
    "hyderabad_df['City']='Hyderabad'\n",
    "\n",
    "# Display the structured dataset\n",
    "print(hyderabad_df.head())\n",
    "\n",
    "# Save the structured data to a new Excel file (optional)\n",
    "hyderabad_df.to_csv('hyderabad_cars.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyderabad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with the correct engine\n",
    "data = pd.read_excel('bangalore_cars.xlsx')\n",
    "\n",
    "# Convert string representations of dictionaries into actual dictionaries\n",
    "data['new_car_detail'] = data['new_car_detail'].apply(ast.literal_eval)\n",
    "data['new_car_overview'] = data['new_car_overview'].apply(ast.literal_eval)\n",
    "data['new_car_feature'] = data['new_car_feature'].apply(ast.literal_eval)\n",
    "data['new_car_specs'] = data['new_car_specs'].apply(ast.literal_eval)\n",
    "\n",
    "# Apply the extraction function to each row\n",
    "bangalore_df = data.apply(extract_details, axis=1)\n",
    "bangalore_df['City']='Bangalore'\n",
    "\n",
    "# Display the structured dataset\n",
    "print(bangalore_df.head())\n",
    "\n",
    "# Save the structured data to a new Excel file (optional)\n",
    "bangalore_df.to_csv('bangalore_cars.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bangalore_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with the correct engine\n",
    "data = pd.read_excel('delhi_cars.xlsx')\n",
    "\n",
    "# Convert string representations of dictionaries into actual dictionaries\n",
    "data['new_car_detail'] = data['new_car_detail'].apply(ast.literal_eval)\n",
    "data['new_car_overview'] = data['new_car_overview'].apply(ast.literal_eval)\n",
    "data['new_car_feature'] = data['new_car_feature'].apply(ast.literal_eval)\n",
    "data['new_car_specs'] = data['new_car_specs'].apply(ast.literal_eval)\n",
    "\n",
    "# Apply the extraction function to each row\n",
    "delhi_df = data.apply(extract_details, axis=1)\n",
    "delhi_df['City']='Delhi'\n",
    "\n",
    "# Display the structured dataset\n",
    "print(delhi_df.head())\n",
    "\n",
    "# Save the structured data to a new Excel file (optional)\n",
    "delhi_df.to_csv('delhi_cars.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delhi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with the correct engine\n",
    "data = pd.read_excel('kolkata_cars.xlsx')\n",
    "\n",
    "# Convert string representations of dictionaries into actual dictionaries\n",
    "data['new_car_detail'] = data['new_car_detail'].apply(ast.literal_eval)\n",
    "data['new_car_overview'] = data['new_car_overview'].apply(ast.literal_eval)\n",
    "data['new_car_feature'] = data['new_car_feature'].apply(ast.literal_eval)\n",
    "data['new_car_specs'] = data['new_car_specs'].apply(ast.literal_eval)\n",
    "\n",
    "# Apply the extraction function to each row\n",
    "kolkata_df = data.apply(extract_details, axis=1)\n",
    "kolkata_df['City']='Kolkata'\n",
    "\n",
    "# Display the structured dataset\n",
    "print(kolkata_df.head())\n",
    "\n",
    "# Save the structured data to a new Excel file (optional)\n",
    "kolkata_df.to_csv('kolkata_cars.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kolkata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with the correct engine\n",
    "data = pd.read_excel('jaipur_cars.xlsx')\n",
    "\n",
    "# Convert string representations of dictionaries into actual dictionaries\n",
    "data['new_car_detail'] = data['new_car_detail'].apply(ast.literal_eval)\n",
    "data['new_car_overview'] = data['new_car_overview'].apply(ast.literal_eval)\n",
    "data['new_car_feature'] = data['new_car_feature'].apply(ast.literal_eval)\n",
    "data['new_car_specs'] = data['new_car_specs'].apply(ast.literal_eval)\n",
    "\n",
    "# Apply the extraction function to each row\n",
    "jaipur_df = data.apply(extract_details, axis=1)\n",
    "jaipur_df['City']=\"Jaipur\"\n",
    "\n",
    "# Display the structured dataset\n",
    "print(jaipur_df.head())\n",
    "\n",
    "# Save the structured data to a new Excel file (optional)\n",
    "jaipur_df.to_csv('jaipur_cars.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([kolkata_df,bangalore_df,chennai_df,delhi_df,hyderabad_df,jaipur_df],axis=0,ignore_index=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some prices in crores so creating a function to conert into lakhs and removing strings like 'Lakh' and 'Crore'\n",
    "\n",
    "def convert_price_to_lakh(price_str):\n",
    "    if 'Lakh' in price_str:\n",
    "        # Remove 'Lakh' and convert to float\n",
    "        return float(price_str.replace('₹', '').replace('Lakh', '').strip())\n",
    "    elif 'Crore' in price_str:\n",
    "        # Remove 'Crore', convert to float, and multiply by 100 to get Lakh\n",
    "        return float(price_str.replace('₹', '').replace('Crore', '').strip()) * 100\n",
    "    else:\n",
    "         #convert thousands value into lakhs\n",
    "         return float(price_str.replace('₹', '').replace(',', '').strip()) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['price'] = combined_df['price'].apply(convert_price_to_lakh)\n",
    "combined_df['price'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_df = combined_df.replace(',', '', regex=True)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting numeric part from strings\n",
    "\n",
    "def extract_numeric(value):\n",
    "    if isinstance(value, str):  # Check if the value is a string\n",
    "        match = re.search(r'\\d+\\.?\\d*', value)  # Use regex to find the first numeric value\n",
    "        if match:\n",
    "            return float(match.group())  # Return the numeric part as a float\n",
    "    return None  # Return None if no match is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to apply the function to\n",
    "columns = ['kilometers_driven','kms_driven','engine_displacement','engine','max_power',\n",
    "                    'torque','wheel_size','seats','length','width', 'height','wheel_base', 'kerb_weight', 'cargo_volumn',\n",
    "                    'displacement','engine_max_power','engine_max_torque','gear_box','seating_capacity','alloy_wheel_size',\n",
    "                   'no_of_doors','registration_year']\n",
    "\n",
    "# Applying the extract_numeric function to all specified columns\n",
    "combined_df[columns] = combined_df[columns].applymap(extract_numeric)\n",
    "\n",
    "# Checking the cleaned data\n",
    "combined_df[columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalize column values and replace with dictionary\n",
    "def normalize_and_replace(combined_df, column, replace_dict):\n",
    "    # Normalize spaces and lowercase the column\n",
    "    combined_df[column] = combined_df[column].str.strip().str.lower()\n",
    "    \n",
    "    # Apply replacements from the dictionary\n",
    "    for standard_value, variations in replace_dict.items():\n",
    "        combined_df[column].replace(variations, standard_value, inplace=True)\n",
    "    \n",
    "    # Return the updated dataframe\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for 'fuel_suppy_system' replacements\n",
    "body_type_replace = {'unknown': ['']}\n",
    "\n",
    "insurance_replace = {'third party': ['third party insurance']}\n",
    "\n",
    "fuel_system_replace = {\n",
    "    'pgm-fi': ['pgm - fi', 'pgm-fi (programmed fuel injection)', 'pgm-fi (programmed fuel inje', 'pgm-fi (programmed fuel inject'],\n",
    "    'efi': ['efi (electronic fuel injection)', 'efi(electronic fuel injection)', 'electronic injection system', 'electronic fuel injection', 'electronic fuel injection(efi)', 'efi (electronic fuel injection', 'efic'],\n",
    "    'mpfi': ['mpfi ', 'mfi ', 'multi point fuel injection'],\n",
    "    'mpi': ['multi-point injection', 'multipoint injection'],\n",
    "    'crdi': ['crdi ', 'common rail direct injection (dci)', 'common rail direct injection', 'direct injection common rail ', 'direct injection common rail'],\n",
    "    'common-rail': ['common rail', 'common rail ', 'common rail diesel', 'common rail injection', 'common rail system', 'common-rail type'],\n",
    "    'direct injection': ['direct injectio', 'direct fuel injection', 'direct injection ', 'direct injection common rail'],\n",
    "}\n",
    "\n",
    "# Dictionary for 'drive_type' replacements\n",
    "drive_type_replace = {\n",
    "    '2wd': ['2 wd', 'two wheel drive', '4x2'],\n",
    "    'fwd': ['front wheel drive'],\n",
    "    'awd': ['all wheel drive'],\n",
    "    '4wd': ['4 wd', '4x4'],\n",
    "}\n",
    "\n",
    "# Dictionary for 'steering_type' replacements\n",
    "steering_type_replace = {\n",
    "    'electric': ['electronic', 'electrical']\n",
    "}\n",
    "\n",
    "\n",
    "# Dictionary for 'front_brake_type' replacements\n",
    "front_brake_type_replace = {\n",
    "    'ventilated disc': ['ventilated discs','ventilated disk','ventlated disc','ventillated disc',' ventilated disc',\n",
    "                       'caliper ventilated disc','booster assisted ventilated disc','discinternally ventilated','vantilated disc'],\n",
    "    'disc': ['disk',' disc','disc brakes','discs','disc brakes','disc 236 mm']    \n",
    "}\n",
    "\n",
    "\n",
    "# Dictionary for 'rear_brake_type' replacements\n",
    "rear_brake_type_replace = {\n",
    "    'ventilated disc': ['ventilated discs','ventilated disc ','ventialte disc'],\n",
    "    'disc': ['discs',' disc'],\n",
    "    'drum': ['drums','drums 180 mm','drum ','drum`','drums 180 mm','228.6 mm dia drums on rear wheels'],\n",
    "    'self-adjusting drum': ['self adjusting drums'], \n",
    "    'leading-trailing drum': ['leading & trailing drum'],\n",
    "    'disc & drum': ['drum in disc','drum in discs'],   \n",
    "}\n",
    "\n",
    "\n",
    "# Dictionary for 'tyre_type_replace' replacements\n",
    "tyre_type_replace = {\n",
    "    'tubeless radial': ['tubelessradial','radial tubeless','radial tubless','tubeless tyres radial','tubelessradial','radialtubeless',\n",
    "                       'tubeless radial tyres','tubelessradials','tubless radial','tublessradial','tubeless radials','tubeless radials tyre',\n",
    "                       ],\n",
    "    'tubeless runflat': ['tubelessrunflat','tubeless. runflat','tubeless. runflat','tubeless runflat' ],\n",
    "    'run-flat': ['runflat',' runflat tyres','runflat tyre','runflatradial','radial with tube','runflat tyres'],\n",
    "    'tubeless': ['tubeless','tubeless tyres','tubeless tyre','tubeless tyres mud terrain','tubeless tyres all terrain'], \n",
    "    'radial': ['radial','radial tyres'],   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization and replacement for each column\n",
    "combined_df = normalize_and_replace(combined_df, 'body_type', body_type_replace)\n",
    "combined_df = normalize_and_replace(combined_df, 'insurance', insurance_replace)\n",
    "combined_df = normalize_and_replace(combined_df, 'fuel_suppy_system', fuel_system_replace)\n",
    "combined_df = normalize_and_replace(combined_df, 'drive_type', drive_type_replace)\n",
    "combined_df = normalize_and_replace(combined_df, 'steering_type', steering_type_replace)\n",
    "combined_df = normalize_and_replace(combined_df, 'front_brake_type', front_brake_type_replace)\n",
    "combined_df = normalize_and_replace(combined_df, 'rear_brake_type', rear_brake_type_replace)\n",
    "combined_df = normalize_and_replace(combined_df, 'tyre_type', tyre_type_replace)\n",
    "\n",
    "\n",
    "# Verify the changes\n",
    "print(combined_df['body_type'].value_counts())\n",
    "print(combined_df['insurance'].value_counts())\n",
    "print(combined_df['fuel_suppy_system'].value_counts())\n",
    "print(combined_df['drive_type'].value_counts())\n",
    "print(combined_df['steering_type'].value_counts())\n",
    "print(combined_df['front_brake_type'].value_counts())\n",
    "print(combined_df['rear_brake_type'].value_counts())\n",
    "print(combined_df['tyre_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these columns have many unique values enconding and using them reduces mode efficiency so dropping them\n",
    "\n",
    "\n",
    "combined_df = combined_df.drop(['ignition_type','Fuel_type','owner','priceActual','priceSaving','trendingText','kms_driven','ownership',\n",
    "              'year_of_manufacture','engine_max_power','engine_max_torque','seating_capacity','priceFixedText',\n",
    "              'heading','Transmission','engine_displacement','displacement'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "combined_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If registration year is missing, filling it with the model year\n",
    "\n",
    "combined_df['registration_year'].fillna(combined_df['model_year'], inplace=True)\n",
    "combined_df['insurance'].fillna('not available', inplace=True)\n",
    "combined_df['rto'].fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values with the mean in numerical columns\n",
    "\n",
    "columns = ['engine', 'max_power', 'torque','wheel_size','length','width',\n",
    "           'height','wheel_base','kerb_weight','cargo_volumn','alloy_wheel_size']\n",
    "\n",
    "# Loop over the columns and fill missing values with the median\n",
    "for column in columns:\n",
    "    combined_df[column].fillna(combined_df[column].mean(), inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "print(combined_df[columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling with mode in categorical columns\n",
    "\n",
    "columns = ['color', 'engine_type','front_brake_type','rear_brake_type','tyre_type']\n",
    "\n",
    "# Loop over the columns and fill missing values with the mode\n",
    "for column in columns:\n",
    "   combined_df[column].fillna(combined_df[column].mode()[0], inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "print(combined_df[columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling with median in numerical columns\n",
    "\n",
    "columns = ['seats', 'no_of_doors','no_of_cylinders','values_per_cylinder','gear_box']\n",
    "\n",
    "# Loop over the columns and fill missing values with the median\n",
    "for column in columns:\n",
    "    combined_df[column].fillna(combined_df[column].median(), inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "print(combined_df[columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing null values with unknown \n",
    "\n",
    "columns = ['fuel_suppy_system','turbo_charger','drive_type','steering_type']\n",
    "\n",
    "\n",
    "for column in columns:\n",
    "    combined_df[column].fillna('unknown', inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "print(combined_df[columns].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking null values \n",
    "\n",
    "combined_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the cleaned data set\n",
    "\n",
    "combined_df.to_csv('Cleaned_new_data.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
